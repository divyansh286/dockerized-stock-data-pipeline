                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Alpha Vantage API   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ JSON Response
                                    â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Python Fetch Script          â”‚
                      â”‚ fetch_and_update.py          â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ Writes to DB
                                 â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  PostgreSQL + pgAdmin          â”‚
                     â”‚   (Docker Container)           â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ Trigger
                                 â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     Apache Airflow (Webserver +        â”‚
                â”‚     Scheduler + DAG Orchestrator)      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ğŸ“¦ Dockerized Stock Market Data Pipeline  
### *(Airflow + PostgreSQL + Docker Compose)*

This project implements a fully **dockerized, automated data pipeline** that fetches intraday stock market data from the **AlphaVantage API**, processes it using Python, and stores it in a **PostgreSQL database**.  
The entire workflow is orchestrated using **Apache Airflow**, and all services run seamlessly inside **Docker containers**.

This submission aligns 100% with the original assignment requirements.

---

## ğŸš€ Features

- Automated stock data ingestion every hour (Airflow DAG)
- Fetches live JSON data using Python `requests`
- Extracts open, high, low, close, volume, timestamp
- Data is validated, parsed, and stored in PostgreSQL
- UPSERT logic prevents duplicate rows
- Error handling with retries & logging
- Fully managed via Docker Compose
- pgAdmin UI included for database visibility
- Secrets and credentials stored via `.env`

---

## ğŸ§± Architecture Overview
Docker Compose
â”‚
â”œâ”€â”€ PostgreSQL (Database)
â”œâ”€â”€ pgAdmin (DB UI)
â””â”€â”€ Airflow
â”œâ”€â”€ Webserver
â”œâ”€â”€ Scheduler
â”œâ”€â”€ DAG: stock_pipeline_dag.py
â””â”€â”€ Python Script: fetch_and_update.py

**Flow:**  
Airflow â†’ Python Script â†’ AlphaVantage API â†’ Extract Metrics â†’ UPSERT into PostgreSQL â†’ Logs stored in Airflow.

---

## ğŸ—‚ Project Structure
stock-pipeline/
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â””â”€â”€ stock_pipeline_dag.py
â”‚ â”œâ”€â”€ scripts/
â”‚ â”‚ â””â”€â”€ fetch_and_update.py
â”‚ â”œâ”€â”€ airflow.cfg
â”‚ â””â”€â”€ logs/
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ fetch_and_update.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ create_table.sql
â”œâ”€â”€ .env
â””â”€â”€ README.md

---

## âš™ï¸ Environment Variables (`.env`)
POSTGRES_USER=stocks_user
POSTGRES_PASSWORD=stocks_pass
POSTGRES_DB=stocks_db
POSTGRES_PORT=5432
POSTGRES_HOST=postgres

API KEY

ALPHA_VANTAGE_API_KEY=your_api_key_here

Fetch multiple stocks (comma-separated)

STOCK_SYMBOLS=AAPL,MSFT,GOOGL,AMZN,TSLA

---

## ğŸ³ How to Run Locally

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/divyansh286/dockerized-stock-data-pipeline.git
cd dockerized-stock-data-pipeline
docker compose up -d
3ï¸âƒ£ Access Services
Service	URL
Airflow UI	http://localhost:8080

pgAdmin	http://localhost:8081

PostgreSQL	localhost:5432
username: admin
password: admin

---
ğŸ”„ How the Pipeline Works
1. Airflow triggers the DAG hourly

DAG file: airflow/dags/stock_pipeline_dag.py

2. Python script fetches JSON data

Script: airflow/scripts/fetch_and_update.py

Extracted fields:

Open price

High price

Low price

Close price

Volume

Symbol

Timestamp

Raw JSON stored for auditing

3. Data written to PostgreSQL

UPSERT logic ensures:

(symbol, api_timestamp) is UNIQUE

4. pgAdmin used for DB monitoring
ğŸ›¡ Error Handling

Wrapped API calls in try/except

Validates JSON schema before use

Logs detailed errors in Airflow

Airflow retries failed tasks automatically

Database errors handled safely

ğŸ“ˆ Scalability

Add more stock symbols in .env

Airflow can scale with Celery/Dockerized workers

PostgreSQL handles large volumes of inserts

Script supports multi-symbol ingestion

ğŸ“œ SQL Table Definition

Defined in create_table.sql:

CREATE TABLE IF NOT EXISTS stock_prices (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(10),
    price NUMERIC,
    open_price NUMERIC,
    high_price NUMERIC,
    low_price NUMERIC,
    close_price NUMERIC,
    volume BIGINT,
    api_timestamp TIMESTAMP,
    fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source VARCHAR(50),
    raw_json JSONB,
    UNIQUE(symbol, api_timestamp)
);

ğŸ§ª Testing the Database

To view the latest inserted rows:

docker exec -it stocks_postgres psql -U stocks_user -d stocks_db -c \
"SELECT symbol, price, api_timestamp, fetched_at FROM stock_prices ORDER BY fetched_at DESC LIMIT 20;"

âœ” Assignment Requirements â€” Fully Met
Requirement	Status
Docker Compose environment	âœ…
Airflow or Dagster orchestrator	âœ… (Airflow)
Fetch data via Python requests	âœ…
Parse JSON & extract metrics	âœ…
Store into PostgreSQL	âœ…
Error handling	âœ…
Environment variables	âœ…
Scalability	âœ…
Clean README	âœ… (this file)
ğŸ§‘â€ğŸ’» Author

Divyansh
Data Engineering & Machine Learning Enthusiast

If you found this useful, â­ the repository!


---

# ğŸ‰ You're Done  
This README is perfectly structured for:

âœ” Assignment submission  
âœ” Professional GitHub presentation  
âœ” Interview demonstration  
âœ” Recruiter review  

If you want, I can now generate:

ğŸ“Œ **Architecture diagram (PNG)**  
ğŸ“Œ **Submission PDF**  
ğŸ“Œ **Viva Q&A answers**  
ğŸ“Œ **Short demo script for Loom video**

Just tell me.





